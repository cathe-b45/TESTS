import { CommonModule } from '@angular/common';
import { Component } from '@angular/core';
import { FormsModule } from '@angular/forms';
import { ConfirmationService } from 'primeng/api';
import { ButtonModule } from 'primeng/button';
import { CardModule } from 'primeng/card';
import { ConfirmDialogModule } from 'primeng/confirmdialog';
import { DividerModule } from 'primeng/divider';
import { RadioButtonModule } from 'primeng/radiobutton';
import { HeadbarComponent } from '../../../../headbar/headbar.component';
import { Router } from '@angular/router';
import { MessagesModule } from 'primeng/messages';

@Component({
  selector: 'app-test-completo-ssii',
  standalone: true,
  imports: [CommonModule, FormsModule, ButtonModule, DividerModule, CardModule, RadioButtonModule, HeadbarComponent, MessagesModule, ConfirmDialogModule],
  providers: [ConfirmationService],
  templateUrl: './test-completo-ssii.component.html',
  styleUrl: './test-completo-ssii.component.scss'
})
export class TestCompletoSsiiComponent {
  temas: { [key: string]: any[] } = {
    "Tema 3": [
        {
            pregunta: "En el enfriamiento simulado la selecci贸n de una peor soluci贸n que la actual depende de:",
            respuestas: [
                "Como de mala es la nueva soluci贸n con respecto a la actual, exclusivamente.",
                "Del tiempo que resta para que el algoritmo termine y de c贸mo de mala es la nueva soluci贸n respecto a la actual.",
                "No se realiza ning煤n cambio bajo esta premisa.",
                "El tiempo que resta hasta que el algoritmo termina (temperatura)"
            ],
            correcta: "Del tiempo que resta para que el algoritmo termine y de c贸mo de mala es la nueva soluci贸n respecto a la actual."
        },
        {
            pregunta: "Con una poblaci贸n de cinco individuos y una funci贸n de aptitud [10,30,20,40] y usando la t茅cnica de selecci贸n de la ruleta, 驴Qu茅 valor es el seleccionado con un valor aleatorio igual a 0.39?",
            respuestas: ["30", "20", "40", "10"],
            correcta: "30"
        },
        {
            pregunta: "La operaci贸n de mutaci贸n en un algoritmo gen茅tico se realiza:",
            respuestas: [
                "combinando los dos individuos generados.",
                "durante la selecci贸n.",
                "antes del cruce y despu茅s de la selecci贸n.",
                "en cada nuevo individuo generado antes de ser a帽adido a la poblaci贸n."
            ],
            correcta: "en cada nuevo individuo generado antes de ser a帽adido a la poblaci贸n."
        },
        {
            pregunta: "Los algoritmos de b煤squeda local son apropiados cuando:",
            respuestas: [
                "la secuencia de acciones es relevante.",
                "el n煤mero de soluciones es m铆nimo.",
                "el factor de ramificaci贸n no es muy alto.",
                "no importa el camino al objetivo."
            ],
            correcta: "no importa el camino al objetivo."
        }
    ],
    "Tema 4": [
        {
            pregunta: "驴Cu谩l de los siguientes algoritmos no es una t茅cnica para la resoluci贸n de PSRs?",
            respuestas: [
                "Comprobaci贸n Hacia Adelante.",
                "B煤squeda con Backtracking.",
                "Todas las dem谩s respuestas son falsas.",
                "Arcos Consistentes."
            ],
            correcta: "Arcos Consistentes"
        },
        {
            pregunta: "Indica la respuesta verdadera relativa al algoritmo AC3:",
            respuestas: [
                "Todas las respuestas son verdaderas.",
                "Se puede considerar una t茅cnica de preprocesamiento.",
                "A veces son capaces de encontrar tambi茅n la soluci贸n del PSR.",
                "La idea es reducir el dominio de las variables al m谩ximo antes de buscar una soluci贸n del PSR."
            ],
            correcta: "Todas las respuestas son verdaderas"
        },
        {
            pregunta: "La restricci贸n A=B, siendo A y B variables, es una relaci贸n unaria:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Falso."
        },
        {
            pregunta: "Una red es arco consistente si:",
            respuestas: [
                "los arcos asociados a las variables principales son consistentes y del resto parcialmente consistentes.",
                "los dominios de las variables contienen un 煤nico valor.",
                "todas las dem谩s respuestas son falsas.",
                "todos sus arcos son consistentes."
            ],
            correcta: "todos sus arcos son consistentes."
        },
        {
            pregunta: "El alcance de una restricci贸n es el conjunto de valores v谩lidos del dominio de las variables afectadas por la restricci贸n:",
            respuestas: ["Verdadero.", "Falso."],
            correcta: "Falso."
        },
        {
            pregunta: "En AC3 un arco X,r(X,Y) necesita ser revisitado si el dominio de Y ha sido reducido:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Verdadero."
        },
        {
            pregunta: "Una soluci贸n de un PSR es una asignaci贸n de un valor a cada variable que satisfaga las restricciones:",
            respuestas: ["Verdadero.", "Falso."],
            correcta: "Verdadero."
        },
        {
            pregunta: "En un PSR modelado como un problema de b煤squeda, un estado es una abstracci贸n del mundo real:",
            respuestas: ["Verdadero.", "Falso."],
            correcta: "Falso."
        },
        {
            pregunta: "La comprobaci贸n hacia adelante proporciona una detecci贸n temprana de todos los fallos:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Falso."
        },
        {
            pregunta: "Indica cu谩l no es una heur铆stica en un PSR.",
            respuestas: [
                "Arcos Consistentes.",
                "Valor Menos Restrictivo.",
                "M铆nimos Valores Restantes.",
                "Grado."
            ],
            correcta: "Arcos Consistentes."
        }
    ],
    "Tema 5": [
        {
            pregunta: "La exploraci贸n en un 谩rbol de juegos se corresponde con la estrategia de b煤squeda:",
            respuestas: ["Primero en Anchura.", "Primero en Profundidad."],
            correcta: "Primero en Profundidad."
        },
        {
            pregunta: "En un 谩rbol de juegos el nodo ra铆z no tiene porque ser siempre un nodo Max:",
            respuestas: ["Verdadero.", "Falso."],
            correcta: "Verdadero."
        },
        {
            pregunta: "La complejidad temporal aproximada asociada a un 谩rbol de juegos para el ajedrez ser铆a:",
            respuestas: ["2*120.", "35*100.", "35^100.", "2^120."],
            correcta: "35^100."
        },
        {
            pregunta: "Indica qu茅 respuesta es falsa relativa a la limitaci贸n de recursos (tiempo y memoria) en la construcci贸n de 谩rboles de juegos:",
            respuestas: [
                "No se puede limitar la profundidad del 谩rbol de juegos porque el rendimiento disminuye de manera cr铆tica.",
                "Se utiliza una funci贸n de evaluaci贸n que estima la deseabilidad de una jugada en vez de una funci贸n de utilidad.",
                "Sabiendo el tiempo m谩ximo de respuesta por jugada o turno se puede determinar la profundidad del 谩rbol a construir.",
                "La calidad del comportamiento esperado se mantiene bajo cualquier transformaci贸n mon贸tona de la funci贸n de evaluaci贸n."
            ],
            correcta: "No se puede limitar la profundidad del 谩rbol de juegos porque el rendimiento disminuye de manera cr铆tica."
        },
        {
            pregunta: "En un 谩rbol minimax para m煤ltiples jugadores (m谩s de 2):",
            respuestas: [
                "Todas las respuestas son verdaderas.",
                "Todos los jugadores son Max.",
                "Cada nivel est谩 asignado a un jugador.",
                "La funci贸n de evaluaci贸n viene dada por un vector."
            ],
            correcta: "Todas las respuestas son verdaderas."
        },
        {
            pregunta: "Indica qu茅 respuesta es falsa relativa a la poda alfa-beta:",
            respuestas: [
                "Alfa es el mejor valor (para max) encontrado en el camino actual.",
                "La poda afecta el resultado final.",
                "Una ordenaci贸n concreta de los posibles movimientos mejora la efectividad de la poda.",
                "Beta es el mejor valor (para min) encontrado en el camino actual."
            ],
            correcta: "La poda afecta el resultado final."
        },
        {
            pregunta: "驴Cu谩l de las siguientes definiciones se corresponde con la de Valor Minimax?:",
            respuestas: [
                "Todas las dem谩s respuestas son falsas.",
                "Minimizaci贸n de la profundidad M谩xima del 谩rbol para acotar el tiempo de respuesta.",
                "Movimiento para cada posible respuesta del oponente.",
                "Mayor recompensa alcanzable contra la mejor jugada."
            ],
            correcta: "Mayor recompensa alcanzable contra la mejor jugada."
        },
        {
            pregunta: "En este tema se estudian las t茅cnicas concretas asociadas a juegos no determin铆sticos con informaci贸n perfecta:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Falso."
        },
        {
            pregunta: "Cada nueva jugada del computador se debe construir el 谩rbol de juegos completo:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Verdadero."
        },
        {
            pregunta: "Con una ordenaci贸n perfecta la poda alfa-beta puede triplicar la profundidad solucionable:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Falso."
        }
    ],
    "Tema 6": [
        {
            pregunta: "Indique cu谩l de las siguientes afirmaciones es verdadera:",
            respuestas: [
                "En los Procesos de Decisi贸n de Markov, la probabilidad de encontrar al sistema en un estado dado depende s贸lo del estado anterior.",
                "La funci贸n de pol铆tica 贸ptima es la pol铆tica que maximiza la utilidad esperada.",
                "Todas las respuestas son verdaderas.",
                "La funci贸n asociada a la pol铆tica selecciona la acci贸n apropiada dado el estado actual."
            ],
            correcta: "Todas las respuestas son verdaderas."
        },
        {
            pregunta: "Indica qu茅 respuesta es falsa relativa al algoritmo de iteraci贸n de valores:",
            respuestas: [
                "Su objetivo es determinar la pol铆tica 贸ptima para cada estado.",
                "Termina cuando se alcanza un nivel de convergencia aceptable.",
                "La recompensa de un estado viene determinada por la elecci贸n de una pol铆tica.",
                "Se basa en la ecuaci贸n de Bellman."
            ],
            correcta: "La recompensa de un estado viene determinada por la elecci贸n de una pol铆tica."
        },
        {
            pregunta: "Cu谩l de las siguientes frases se puede considerar como un posible resultado del aprendizaje:",
            respuestas: [
                "El rango de comportamientos puede ser expandido: el agente puede hacer m谩s.",
                "La precisi贸n en tareas es mejorada: el agente puede hacer las cosas mejor.",
                "Todas las otras respuestas son verdaderas.",
                "La velocidad se mejora: el agente puede hacer cosas m谩s r谩pido."
            ],
            correcta: "Todas las otras respuestas son verdaderas."
        },
        {
            pregunta: "El factor de descuento determina hasta qu茅 punto la nueva informaci贸n adquirida sobrescribe o sustituye a la informaci贸n anterior:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Falso."
        },
        {
            pregunta: "En el algoritmo de Q-learning si la tasa de aprendizaje es 1, esto har谩 que el agente s贸lo considere la informaci贸n m谩s reciente:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Verdadero."
        },
        {
            pregunta: "La explotaci贸n en aprendizaje por refuerzo utiliza el conocimiento ya aprendido para decidir cu谩l es la mejor acci贸n:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Verdadero."
        },
        {
            pregunta: "La funci贸n de valor representa c贸mo de bueno es un estado para que un agente est茅 en 茅l:",
            respuestas: ["Verdadero.", "Falso."],
            correcta: "Verdadero."
        },
        {
            pregunta: "La Q-tabla tiene una entrada por cada par (estado,recompensa) v谩lido:",
            respuestas: ["Verdadero.", "Falso."],
            correcta: "Falso."
        },
        {
            pregunta: "En los problemas de aprendizaje por refuerzo, la retroalimentaci贸n es:",
            respuestas: [
                "obtenida mediante el algoritmo de iteraci贸n de valores.",
                "la secuencia de acciones que lleva a una mayor recompensa.",
                "un valor escalar que puede retrasarse en el tiempo.",
                "Todas las dem谩s respuestas son falsas."
            ],
            correcta: "un valor escalar que puede retrasarse en el tiempo."
        },
        {
            pregunta: "En aprendizaje por refuerzo, el problema de atribuci贸n de la culpa plantea la dificultad de determinar qu茅 acci贸n era responsable de una recompensa o castigo:",
            respuestas: ["Verdadero.", "Falso."],
            correcta: "Verdadero."
        }
    ]
};

preguntasActuales: any[] = [];
testFinalizado: boolean = false;
respuestasUsuario: string[] = []; // Respuestas seleccionadas por el usuario.

constructor(
  private router: Router,
  private confirmationService: ConfirmationService
) {
  this.cargarPreguntasCompletas();
}

/**
 * Cargar todas las preguntas de todos los temas y mezclarlas.
 */
cargarPreguntasCompletas() {
  const preguntas = [
    ...this.temas["Tema 3"],
    ...this.temas["Tema 4"],
    ...this.temas["Tema 5"],
    ...this.temas["Tema 6"]
  ];
  this.preguntasActuales = this.shuffleArray(preguntas);

  this.preguntasActuales.forEach((pregunta) => {
    pregunta.respuestas = this.shuffleArray(pregunta.respuestas);
  });

  this.respuestasUsuario = new Array(this.preguntasActuales.length).fill(null);
  this.testFinalizado = false;
}

/**
 * Barajar un array aleatoriamente.
 */
shuffleArray(array: any[]): any[] {
  return array.sort(() => Math.random() - 0.5);
}

finalizarTest() {
  let respuestasCorrectas = 0;

  this.preguntasActuales.forEach((pregunta) => {
    if (pregunta.seleccionada === pregunta.correcta) {
      respuestasCorrectas++;
      pregunta.mensajeRespuesta = [
        { severity: 'success', summary: 'Correcto', detail: `La respuesta seleccionada es correcta.` }
      ];
    } else {
      pregunta.mensajeRespuesta = [
        { severity: 'error', summary: 'Respuesta correcta: ', detail: `${pregunta.correcta}` }
      ];
    }
  });

  this.testFinalizado = true;

  this.confirmationService.confirm({
    header: ' Test Finalizado',
    message: `隆Has acertado ${respuestasCorrectas} de ${this.preguntasActuales.length} preguntas!`,
    icon: 'pi pi-check-circle',
    acceptLabel: 'Aceptar',
    rejectVisible: false,
    accept: () => {
      console.log('Test finalizado confirmado');
    }
  });
}

/**
 * Volver a la p谩gina anterior.
 */
goBack() {
  this.router.navigate(['/ssii']);
}
}
