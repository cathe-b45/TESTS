import { CommonModule } from '@angular/common';
import { Component } from '@angular/core';
import { ButtonModule } from 'primeng/button';
import { HeadbarComponent } from '../../../../headbar/headbar.component';
import { Router } from '@angular/router';
import { RadioButtonModule } from 'primeng/radiobutton';
import { FormsModule } from '@angular/forms';
import { CardModule } from 'primeng/card';
import { ConfirmDialogModule } from 'primeng/confirmdialog';
import { ConfirmationService } from 'primeng/api';
import { DividerModule } from 'primeng/divider';
import { MessagesModule } from 'primeng/messages';

@Component({
  selector: 'app-test-temas-ssii',
  standalone: true,
  imports: [CommonModule, FormsModule, ButtonModule,DividerModule, CardModule, RadioButtonModule, HeadbarComponent,MessagesModule, ConfirmDialogModule],
  providers: [ConfirmationService],

  templateUrl: './test-temas-ssii.component.html',
  styleUrl: './test-temas-ssii.component.scss'
})
export class TestTemasSsiiComponent {
  temas: { [key: string]: any[] } = {
    "Tema 3": [
        {
            pregunta: "En el enfriamiento simulado la selecci칩n de una peor soluci칩n que la actual depende de:",
            respuestas: [
                "Como de mala es la nueva soluci칩n con respecto a la actual, exclusivamente.",
                "Del tiempo que resta para que el algoritmo termine y de c칩mo de mala es la nueva soluci칩n respecto a la actual.",
                "No se realiza ning칰n cambio bajo esta premisa.",
                "El tiempo que resta hasta que el algoritmo termina (temperatura)"
            ],
            correcta: "Del tiempo que resta para que el algoritmo termine y de c칩mo de mala es la nueva soluci칩n respecto a la actual."
        },
        {
            pregunta: "Con una poblaci칩n de cinco individuos y una funci칩n de aptitud [10,30,20,40] y usando la t칠cnica de selecci칩n de la ruleta, 쯈u칠 valor es el seleccionado con un valor aleatorio igual a 0.39?",
            respuestas: ["30", "20", "40", "10"],
            correcta: "30"
        },
        {
            pregunta: "La operaci칩n de mutaci칩n en un algoritmo gen칠tico se realiza:",
            respuestas: [
                "combinando los dos individuos generados.",
                "durante la selecci칩n.",
                "antes del cruce y despu칠s de la selecci칩n.",
                "en cada nuevo individuo generado antes de ser a침adido a la poblaci칩n."
            ],
            correcta: "en cada nuevo individuo generado antes de ser a침adido a la poblaci칩n."
        },
        {
            pregunta: "Los algoritmos de b칰squeda local son apropiados cuando:",
            respuestas: [
                "la secuencia de acciones es relevante.",
                "el n칰mero de soluciones es m칤nimo.",
                "el factor de ramificaci칩n no es muy alto.",
                "no importa el camino al objetivo."
            ],
            correcta: "no importa el camino al objetivo."
        }
    ],
    "Tema 4": [
        {
            pregunta: "쮺u치l de los siguientes algoritmos no es una t칠cnica para la resoluci칩n de PSRs?",
            respuestas: [
                "Comprobaci칩n Hacia Adelante.",
                "B칰squeda con Backtracking.",
                "Todas las dem치s respuestas son falsas.",
                "Arcos Consistentes."
            ],
            correcta: "Arcos Consistentes"
        },
        {
            pregunta: "Indica la respuesta verdadera relativa al algoritmo AC3:",
            respuestas: [
                "Todas las respuestas son verdaderas.",
                "Se puede considerar una t칠cnica de preprocesamiento.",
                "A veces son capaces de encontrar tambi칠n la soluci칩n del PSR.",
                "La idea es reducir el dominio de las variables al m치ximo antes de buscar una soluci칩n del PSR."
            ],
            correcta: "Todas las respuestas son verdaderas"
        },
        {
            pregunta: "La restricci칩n A=B, siendo A y B variables, es una relaci칩n unaria:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Falso."
        },
        {
            pregunta: "Una red es arco consistente si:",
            respuestas: [
                "los arcos asociados a las variables principales son consistentes y del resto parcialmente consistentes.",
                "los dominios de las variables contienen un 칰nico valor.",
                "todas las dem치s respuestas son falsas.",
                "todos sus arcos son consistentes."
            ],
            correcta: "todos sus arcos son consistentes."
        },
        {
            pregunta: "El alcance de una restricci칩n es el conjunto de valores v치lidos del dominio de las variables afectadas por la restricci칩n:",
            respuestas: ["Verdadero.", "Falso."],
            correcta: "Falso."
        },
        {
            pregunta: "En AC3 un arco X,r(X,Y) necesita ser revisitado si el dominio de Y ha sido reducido:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Verdadero."
        },
        {
            pregunta: "Una soluci칩n de un PSR es una asignaci칩n de un valor a cada variable que satisfaga las restricciones:",
            respuestas: ["Verdadero.", "Falso."],
            correcta: "Verdadero."
        },
        {
            pregunta: "En un PSR modelado como un problema de b칰squeda, un estado es una abstracci칩n del mundo real:",
            respuestas: ["Verdadero.", "Falso."],
            correcta: "Falso."
        },
        {
            pregunta: "La comprobaci칩n hacia adelante proporciona una detecci칩n temprana de todos los fallos:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Falso."
        },
        {
            pregunta: "Indica cu치l no es una heur칤stica en un PSR.",
            respuestas: [
                "Arcos Consistentes.",
                "Valor Menos Restrictivo.",
                "M칤nimos Valores Restantes.",
                "Grado."
            ],
            correcta: "Arcos Consistentes."
        }
    ],
    "Tema 5": [
        {
            pregunta: "La exploraci칩n en un 치rbol de juegos se corresponde con la estrategia de b칰squeda:",
            respuestas: ["Primero en Anchura.", "Primero en Profundidad."],
            correcta: "Primero en Profundidad."
        },
        {
            pregunta: "En un 치rbol de juegos el nodo ra칤z no tiene porque ser siempre un nodo Max:",
            respuestas: ["Verdadero.", "Falso."],
            correcta: "Verdadero."
        },
        {
            pregunta: "La complejidad temporal aproximada asociada a un 치rbol de juegos para el ajedrez ser칤a:",
            respuestas: ["2*120.", "35*100.", "35^100.", "2^120."],
            correcta: "35^100."
        },
        {
            pregunta: "Indica qu칠 respuesta es falsa relativa a la limitaci칩n de recursos (tiempo y memoria) en la construcci칩n de 치rboles de juegos:",
            respuestas: [
                "No se puede limitar la profundidad del 치rbol de juegos porque el rendimiento disminuye de manera cr칤tica.",
                "Se utiliza una funci칩n de evaluaci칩n que estima la deseabilidad de una jugada en vez de una funci칩n de utilidad.",
                "Sabiendo el tiempo m치ximo de respuesta por jugada o turno se puede determinar la profundidad del 치rbol a construir.",
                "La calidad del comportamiento esperado se mantiene bajo cualquier transformaci칩n mon칩tona de la funci칩n de evaluaci칩n."
            ],
            correcta: "No se puede limitar la profundidad del 치rbol de juegos porque el rendimiento disminuye de manera cr칤tica."
        },
        {
            pregunta: "En un 치rbol minimax para m칰ltiples jugadores (m치s de 2):",
            respuestas: [
                "Todas las respuestas son verdaderas.",
                "Todos los jugadores son Max.",
                "Cada nivel est치 asignado a un jugador.",
                "La funci칩n de evaluaci칩n viene dada por un vector."
            ],
            correcta: "Todas las respuestas son verdaderas."
        },
        {
            pregunta: "Indica qu칠 respuesta es falsa relativa a la poda alfa-beta:",
            respuestas: [
                "Alfa es el mejor valor (para max) encontrado en el camino actual.",
                "La poda afecta el resultado final.",
                "Una ordenaci칩n concreta de los posibles movimientos mejora la efectividad de la poda.",
                "Beta es el mejor valor (para min) encontrado en el camino actual."
            ],
            correcta: "La poda afecta el resultado final."
        },
        {
            pregunta: "쮺u치l de las siguientes definiciones se corresponde con la de Valor Minimax?:",
            respuestas: [
                "Todas las dem치s respuestas son falsas.",
                "Minimizaci칩n de la profundidad M치xima del 치rbol para acotar el tiempo de respuesta.",
                "Movimiento para cada posible respuesta del oponente.",
                "Mayor recompensa alcanzable contra la mejor jugada."
            ],
            correcta: "Mayor recompensa alcanzable contra la mejor jugada."
        },
        {
            pregunta: "En este tema se estudian las t칠cnicas concretas asociadas a juegos no determin칤sticos con informaci칩n perfecta:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Falso."
        },
        {
            pregunta: "Cada nueva jugada del computador se debe construir el 치rbol de juegos completo:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Verdadero."
        },
        {
            pregunta: "Con una ordenaci칩n perfecta la poda alfa-beta puede triplicar la profundidad solucionable:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Falso."
        }
    ],
    "Tema 6": [
        {
            pregunta: "Indique cu치l de las siguientes afirmaciones es verdadera:",
            respuestas: [
                "En los Procesos de Decisi칩n de Markov, la probabilidad de encontrar al sistema en un estado dado depende s칩lo del estado anterior.",
                "La funci칩n de pol칤tica 칩ptima es la pol칤tica que maximiza la utilidad esperada.",
                "Todas las respuestas son verdaderas.",
                "La funci칩n asociada a la pol칤tica selecciona la acci칩n apropiada dado el estado actual."
            ],
            correcta: "Todas las respuestas son verdaderas."
        },
        {
            pregunta: "Indica qu칠 respuesta es falsa relativa al algoritmo de iteraci칩n de valores:",
            respuestas: [
                "Su objetivo es determinar la pol칤tica 칩ptima para cada estado.",
                "Termina cuando se alcanza un nivel de convergencia aceptable.",
                "La recompensa de un estado viene determinada por la elecci칩n de una pol칤tica.",
                "Se basa en la ecuaci칩n de Bellman."
            ],
            correcta: "La recompensa de un estado viene determinada por la elecci칩n de una pol칤tica."
        },
        {
            pregunta: "Cu치l de las siguientes frases se puede considerar como un posible resultado del aprendizaje:",
            respuestas: [
                "El rango de comportamientos puede ser expandido: el agente puede hacer m치s.",
                "La precisi칩n en tareas es mejorada: el agente puede hacer las cosas mejor.",
                "Todas las otras respuestas son verdaderas.",
                "La velocidad se mejora: el agente puede hacer cosas m치s r치pido."
            ],
            correcta: "Todas las otras respuestas son verdaderas."
        },
        {
            pregunta: "El factor de descuento determina hasta qu칠 punto la nueva informaci칩n adquirida sobrescribe o sustituye a la informaci칩n anterior:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Falso."
        },
        {
            pregunta: "En el algoritmo de Q-learning si la tasa de aprendizaje es 1, esto har치 que el agente s칩lo considere la informaci칩n m치s reciente:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Verdadero."
        },
        {
            pregunta: "La explotaci칩n en aprendizaje por refuerzo utiliza el conocimiento ya aprendido para decidir cu치l es la mejor acci칩n:",
            respuestas: ["Falso.", "Verdadero."],
            correcta: "Verdadero."
        },
        {
            pregunta: "La funci칩n de valor representa c칩mo de bueno es un estado para que un agente est칠 en 칠l:",
            respuestas: ["Verdadero.", "Falso."],
            correcta: "Verdadero."
        },
        {
            pregunta: "La Q-tabla tiene una entrada por cada par (estado,recompensa) v치lido:",
            respuestas: ["Verdadero.", "Falso."],
            correcta: "Falso."
        },
        {
            pregunta: "En los problemas de aprendizaje por refuerzo, la retroalimentaci칩n es:",
            respuestas: [
                "obtenida mediante el algoritmo de iteraci칩n de valores.",
                "la secuencia de acciones que lleva a una mayor recompensa.",
                "un valor escalar que puede retrasarse en el tiempo.",
                "Todas las dem치s respuestas son falsas."
            ],
            correcta: "un valor escalar que puede retrasarse en el tiempo."
        },
        {
            pregunta: "En aprendizaje por refuerzo, el problema de atribuci칩n de la culpa plantea la dificultad de determinar qu칠 acci칩n era responsable de una recompensa o castigo:",
            respuestas: ["Verdadero.", "Falso."],
            correcta: "Verdadero."
        }
    ]
};
temaActual: number = 0;
  temasKeys: string[] = [];
  preguntasActuales: any[] = [];
  tituloTema: string = '';
  testFinalizado: boolean = false;
  respuestasUsuario: string[] = []; // Array para almacenar respuestas seleccionadas por el usuario.

 constructor(
    private router: Router,
    private confirmationService: ConfirmationService
  ) {
    this.temasKeys = Object.keys(this.temas);
    this.cargarTemaActual();
  }


  /**
   * Cargar las preguntas de un tema espec칤fico y barajar preguntas y respuestas.
   */
  cargarTemaActual() {
    this.tituloTema = this.temasKeys[this.temaActual];
    this.preguntasActuales = this.shuffleArray(this.temas[this.tituloTema]);

    this.preguntasActuales.forEach((pregunta) => {
      pregunta.respuestas = this.shuffleArray(pregunta.respuestas);
    });

    this.respuestasUsuario = new Array(this.preguntasActuales.length).fill(null);
    this.testFinalizado = false;
  }

  /**
   * Barajar un array aleatoriamente.
   */
  shuffleArray(array: any[]): any[] {
    return array.sort(() => Math.random() - 0.5);
  }

  /**
   * Navegar al siguiente tema.
   */
  siguienteTema() {
    if (this.temaActual < this.temasKeys.length - 1) {
      this.temaActual++;
      this.cargarTemaActual();
    } else {
      alert('춰Has completado todos los temas!');
    }
  }

  /**
   * Navegar al tema anterior.
   */
  temaAnterior() {
    if (this.temaActual > 0) {
      this.temaActual--;
      this.cargarTemaActual();
    } else {
      alert('Est치s en el primer tema.');
    }
  }

  /**
   * Finalizar el test y mostrar respuestas correctas.
   */
  
finalizarTest() {
  let respuestasCorrectas = 0;

  this.preguntasActuales.forEach((pregunta) => {
    if (pregunta.seleccionada === pregunta.correcta) {
      respuestasCorrectas++;
      pregunta.mensajeRespuesta = [
        { severity: 'success', summary: 'Correcto', detail: `La respuesta seleccionada es correcta.` }
      ];
    } else {
      pregunta.mensajeRespuesta = [
        { severity: 'error', summary: 'Respuesta correcta: ', detail: `${pregunta.correcta}` }
      ];
    }
  });

  this.testFinalizado = true;

  this.confirmationService.confirm({
    header: '游꿢 Test Finalizado',
    message: `춰Has acertado ${respuestasCorrectas} de ${this.preguntasActuales.length} preguntas!`,
    icon: 'pi pi-check-circle',
    acceptLabel: 'Aceptar',
    rejectVisible: false,
    accept: () => {
      console.log('Test finalizado confirmado');
    }
  });
}
  /**
   * Volver a la p치gina anterior.
   */
  goBack() {
    this.router.navigate(['/ssii']);
  }
}
